{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://datascienceplus.com/keras-regression-based-neural-networks/\n"
     ]
    }
   ],
   "source": [
    "print(\"https://datascienceplus.com/keras-regression-based-neural-networks/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "loadtxt() got an unexpected keyword argument 'header'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-9b94e0b86ae3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\nCalo\\Documents\\Automifai\\Research\\Coding Lessons\\Keras\\Data sets\\cars.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: loadtxt() got an unexpected keyword argument 'header'"
     ]
    }
   ],
   "source": [
    "#Variables\n",
    "dataset=np.loadtxt(r'C:\\Users\\nCalo\\Documents\\Automifai\\Research\\Coding Lessons\\Keras\\Data sets\\cars.csv', header = 0, index_col = 0, delimiter=\",\")\n",
    "x=dataset[:,0:5]\n",
    "y=dataset[:,5]\n",
    "y=np.reshape(y, (-1,1))\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "print(scaler_x.fit(x))\n",
    "xscale=scaler_x.transform(x)\n",
    "print(scaler_y.fit(y))\n",
    "yscale=scaler_y.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(xscale, yscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 12)                72        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 185\n",
      "Trainable params: 185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=5, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 577 samples, validate on 145 samples\n",
      "Epoch 1/150\n",
      "577/577 [==============================] - 1s 1ms/sample - loss: 0.1920 - mse: 0.1920 - mae: 0.3257 - val_loss: 0.1379 - val_mse: 0.1379 - val_mae: 0.2745\n",
      "Epoch 2/150\n",
      "577/577 [==============================] - 0s 78us/sample - loss: 0.1457 - mse: 0.1457 - mae: 0.2760 - val_loss: 0.0995 - val_mse: 0.0995 - val_mae: 0.2370\n",
      "Epoch 3/150\n",
      "577/577 [==============================] - 0s 70us/sample - loss: 0.1039 - mse: 0.1039 - mae: 0.2428 - val_loss: 0.0685 - val_mse: 0.0685 - val_mae: 0.2112\n",
      "Epoch 4/150\n",
      "577/577 [==============================] - 0s 106us/sample - loss: 0.0714 - mse: 0.0714 - mae: 0.2228 - val_loss: 0.0569 - val_mse: 0.0569 - val_mae: 0.2075\n",
      "Epoch 5/150\n",
      "577/577 [==============================] - 0s 69us/sample - loss: 0.0603 - mse: 0.0603 - mae: 0.2166 - val_loss: 0.0567 - val_mse: 0.0567 - val_mae: 0.2090\n",
      "Epoch 6/150\n",
      "577/577 [==============================] - 0s 79us/sample - loss: 0.0569 - mse: 0.0569 - mae: 0.2119 - val_loss: 0.0533 - val_mse: 0.0533 - val_mae: 0.2022\n",
      "Epoch 7/150\n",
      "577/577 [==============================] - 0s 81us/sample - loss: 0.0527 - mse: 0.0527 - mae: 0.2035 - val_loss: 0.0484 - val_mse: 0.0484 - val_mae: 0.1924\n",
      "Epoch 8/150\n",
      "577/577 [==============================] - 0s 64us/sample - loss: 0.0487 - mse: 0.0487 - mae: 0.1948 - val_loss: 0.0444 - val_mse: 0.0444 - val_mae: 0.1838\n",
      "Epoch 9/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0449 - mse: 0.0449 - mae: 0.1862 - val_loss: 0.0405 - val_mse: 0.0405 - val_mae: 0.1748\n",
      "Epoch 10/150\n",
      "577/577 [==============================] - 0s 69us/sample - loss: 0.0410 - mse: 0.0410 - mae: 0.1769 - val_loss: 0.0371 - val_mse: 0.0371 - val_mae: 0.1661\n",
      "Epoch 11/150\n",
      "577/577 [==============================] - 0s 66us/sample - loss: 0.0373 - mse: 0.0373 - mae: 0.1674 - val_loss: 0.0338 - val_mse: 0.0338 - val_mae: 0.1576\n",
      "Epoch 12/150\n",
      "577/577 [==============================] - 0s 71us/sample - loss: 0.0340 - mse: 0.0340 - mae: 0.1584 - val_loss: 0.0307 - val_mse: 0.0307 - val_mae: 0.1486\n",
      "Epoch 13/150\n",
      "577/577 [==============================] - 0s 69us/sample - loss: 0.0305 - mse: 0.0305 - mae: 0.1484 - val_loss: 0.0269 - val_mse: 0.0269 - val_mae: 0.1376\n",
      "Epoch 14/150\n",
      "577/577 [==============================] - 0s 73us/sample - loss: 0.0271 - mse: 0.0271 - mae: 0.1378 - val_loss: 0.0242 - val_mse: 0.0242 - val_mae: 0.1282\n",
      "Epoch 15/150\n",
      "577/577 [==============================] - 0s 71us/sample - loss: 0.0245 - mse: 0.0245 - mae: 0.1286 - val_loss: 0.0219 - val_mse: 0.0219 - val_mae: 0.1194\n",
      "Epoch 16/150\n",
      "577/577 [==============================] - 0s 78us/sample - loss: 0.0223 - mse: 0.0223 - mae: 0.1206 - val_loss: 0.0199 - val_mse: 0.0199 - val_mae: 0.1117\n",
      "Epoch 17/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0206 - mse: 0.0206 - mae: 0.1139 - val_loss: 0.0180 - val_mse: 0.0180 - val_mae: 0.1045\n",
      "Epoch 18/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0194 - mse: 0.0194 - mae: 0.1086 - val_loss: 0.0171 - val_mse: 0.0171 - val_mae: 0.1009\n",
      "Epoch 19/150\n",
      "577/577 [==============================] - 0s 73us/sample - loss: 0.0185 - mse: 0.0185 - mae: 0.1051 - val_loss: 0.0164 - val_mse: 0.0164 - val_mae: 0.0979\n",
      "Epoch 20/150\n",
      "577/577 [==============================] - 0s 78us/sample - loss: 0.0180 - mse: 0.0180 - mae: 0.1025 - val_loss: 0.0157 - val_mse: 0.0157 - val_mae: 0.0951\n",
      "Epoch 21/150\n",
      "577/577 [==============================] - 0s 70us/sample - loss: 0.0176 - mse: 0.0176 - mae: 0.1005 - val_loss: 0.0152 - val_mse: 0.0152 - val_mae: 0.0932\n",
      "Epoch 22/150\n",
      "577/577 [==============================] - 0s 71us/sample - loss: 0.0174 - mse: 0.0174 - mae: 0.0992 - val_loss: 0.0151 - val_mse: 0.0151 - val_mae: 0.0926\n",
      "Epoch 23/150\n",
      "577/577 [==============================] - 0s 73us/sample - loss: 0.0172 - mse: 0.0172 - mae: 0.0990 - val_loss: 0.0149 - val_mse: 0.0149 - val_mae: 0.0917\n",
      "Epoch 24/150\n",
      "577/577 [==============================] - 0s 69us/sample - loss: 0.0171 - mse: 0.0171 - mae: 0.0985 - val_loss: 0.0145 - val_mse: 0.0145 - val_mae: 0.0901\n",
      "Epoch 25/150\n",
      "577/577 [==============================] - 0s 73us/sample - loss: 0.0170 - mse: 0.0170 - mae: 0.0980 - val_loss: 0.0144 - val_mse: 0.0144 - val_mae: 0.0900\n",
      "Epoch 26/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0170 - mse: 0.0170 - mae: 0.0978 - val_loss: 0.0144 - val_mse: 0.0144 - val_mae: 0.0898\n",
      "Epoch 27/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0169 - mse: 0.0169 - mae: 0.0978 - val_loss: 0.0144 - val_mse: 0.0144 - val_mae: 0.0897\n",
      "Epoch 28/150\n",
      "577/577 [==============================] - 0s 75us/sample - loss: 0.0168 - mse: 0.0168 - mae: 0.0976 - val_loss: 0.0143 - val_mse: 0.0143 - val_mae: 0.0897\n",
      "Epoch 29/150\n",
      "577/577 [==============================] - 0s 80us/sample - loss: 0.0168 - mse: 0.0168 - mae: 0.0977 - val_loss: 0.0143 - val_mse: 0.0143 - val_mae: 0.0892\n",
      "Epoch 30/150\n",
      "577/577 [==============================] - 0s 99us/sample - loss: 0.0168 - mse: 0.0168 - mae: 0.0973 - val_loss: 0.0140 - val_mse: 0.0140 - val_mae: 0.0884\n",
      "Epoch 31/150\n",
      "577/577 [==============================] - 0s 62us/sample - loss: 0.0172 - mse: 0.0172 - mae: 0.0995 - val_loss: 0.0146 - val_mse: 0.0146 - val_mae: 0.0903\n",
      "Epoch 32/150\n",
      "577/577 [==============================] - 0s 61us/sample - loss: 0.0167 - mse: 0.0167 - mae: 0.0967 - val_loss: 0.0138 - val_mse: 0.0138 - val_mae: 0.0873\n",
      "Epoch 33/150\n",
      "577/577 [==============================] - 0s 66us/sample - loss: 0.0167 - mse: 0.0167 - mae: 0.0971 - val_loss: 0.0142 - val_mse: 0.0142 - val_mae: 0.0889\n",
      "Epoch 34/150\n",
      "577/577 [==============================] - 0s 69us/sample - loss: 0.0165 - mse: 0.0165 - mae: 0.0966 - val_loss: 0.0140 - val_mse: 0.0140 - val_mae: 0.0885\n",
      "Epoch 35/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0165 - mse: 0.0165 - mae: 0.0963 - val_loss: 0.0140 - val_mse: 0.0140 - val_mae: 0.0884\n",
      "Epoch 36/150\n",
      "577/577 [==============================] - 0s 85us/sample - loss: 0.0164 - mse: 0.0164 - mae: 0.0961 - val_loss: 0.0139 - val_mse: 0.0139 - val_mae: 0.0880\n",
      "Epoch 37/150\n",
      "577/577 [==============================] - 0s 71us/sample - loss: 0.0164 - mse: 0.0164 - mae: 0.0965 - val_loss: 0.0141 - val_mse: 0.0141 - val_mae: 0.0890\n",
      "Epoch 38/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0163 - mse: 0.0163 - mae: 0.0961 - val_loss: 0.0138 - val_mse: 0.0138 - val_mae: 0.0880\n",
      "Epoch 39/150\n",
      "577/577 [==============================] - 0s 75us/sample - loss: 0.0163 - mse: 0.0163 - mae: 0.0959 - val_loss: 0.0138 - val_mse: 0.0138 - val_mae: 0.0880\n",
      "Epoch 40/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0162 - mse: 0.0162 - mae: 0.0955 - val_loss: 0.0137 - val_mse: 0.0137 - val_mae: 0.0875\n",
      "Epoch 41/150\n",
      "577/577 [==============================] - 0s 66us/sample - loss: 0.0162 - mse: 0.0162 - mae: 0.0960 - val_loss: 0.0138 - val_mse: 0.0138 - val_mae: 0.0881\n",
      "Epoch 42/150\n",
      "577/577 [==============================] - 0s 69us/sample - loss: 0.0161 - mse: 0.0161 - mae: 0.0954 - val_loss: 0.0136 - val_mse: 0.0136 - val_mae: 0.0873\n",
      "Epoch 43/150\n",
      "577/577 [==============================] - 0s 64us/sample - loss: 0.0162 - mse: 0.0162 - mae: 0.0951 - val_loss: 0.0138 - val_mse: 0.0138 - val_mae: 0.0878\n",
      "Epoch 44/150\n",
      "577/577 [==============================] - 0s 66us/sample - loss: 0.0161 - mse: 0.0161 - mae: 0.0956 - val_loss: 0.0137 - val_mse: 0.0137 - val_mae: 0.0878\n",
      "Epoch 45/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0161 - mse: 0.0161 - mae: 0.0950 - val_loss: 0.0136 - val_mse: 0.0136 - val_mae: 0.0875\n",
      "Epoch 46/150\n",
      "577/577 [==============================] - 0s 66us/sample - loss: 0.0160 - mse: 0.0160 - mae: 0.0951 - val_loss: 0.0136 - val_mse: 0.0136 - val_mae: 0.0873\n",
      "Epoch 47/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0160 - mse: 0.0160 - mae: 0.0955 - val_loss: 0.0135 - val_mse: 0.0135 - val_mae: 0.0869\n",
      "Epoch 48/150\n",
      "577/577 [==============================] - 0s 66us/sample - loss: 0.0160 - mse: 0.0160 - mae: 0.0949 - val_loss: 0.0136 - val_mse: 0.0136 - val_mae: 0.0877\n",
      "Epoch 49/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0159 - mse: 0.0159 - mae: 0.0946 - val_loss: 0.0134 - val_mse: 0.0134 - val_mae: 0.0868\n",
      "Epoch 50/150\n",
      "577/577 [==============================] - 0s 66us/sample - loss: 0.0158 - mse: 0.0158 - mae: 0.0947 - val_loss: 0.0136 - val_mse: 0.0136 - val_mae: 0.0871\n",
      "Epoch 51/150\n",
      "577/577 [==============================] - 0s 69us/sample - loss: 0.0158 - mse: 0.0158 - mae: 0.0945 - val_loss: 0.0134 - val_mse: 0.0134 - val_mae: 0.0868\n",
      "Epoch 52/150\n",
      "577/577 [==============================] - 0s 88us/sample - loss: 0.0157 - mse: 0.0157 - mae: 0.0943 - val_loss: 0.0135 - val_mse: 0.0135 - val_mae: 0.0870\n",
      "Epoch 53/150\n",
      "577/577 [==============================] - 0s 62us/sample - loss: 0.0157 - mse: 0.0157 - mae: 0.0942 - val_loss: 0.0134 - val_mse: 0.0134 - val_mae: 0.0864\n",
      "Epoch 54/150\n",
      "577/577 [==============================] - 0s 64us/sample - loss: 0.0157 - mse: 0.0157 - mae: 0.0942 - val_loss: 0.0134 - val_mse: 0.0134 - val_mae: 0.0864\n",
      "Epoch 55/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0157 - mse: 0.0157 - mae: 0.0938 - val_loss: 0.0132 - val_mse: 0.0132 - val_mae: 0.0860\n",
      "Epoch 56/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0157 - mse: 0.0157 - mae: 0.0944 - val_loss: 0.0135 - val_mse: 0.0135 - val_mae: 0.0870\n",
      "Epoch 57/150\n",
      "577/577 [==============================] - 0s 69us/sample - loss: 0.0155 - mse: 0.0155 - mae: 0.0934 - val_loss: 0.0132 - val_mse: 0.0132 - val_mae: 0.0859\n",
      "Epoch 58/150\n",
      "577/577 [==============================] - 0s 66us/sample - loss: 0.0155 - mse: 0.0155 - mae: 0.0932 - val_loss: 0.0133 - val_mse: 0.0133 - val_mae: 0.0862\n",
      "Epoch 59/150\n",
      "577/577 [==============================] - 0s 69us/sample - loss: 0.0155 - mse: 0.0155 - mae: 0.0935 - val_loss: 0.0135 - val_mse: 0.0135 - val_mae: 0.0871\n",
      "Epoch 60/150\n",
      "577/577 [==============================] - 0s 66us/sample - loss: 0.0154 - mse: 0.0154 - mae: 0.0929 - val_loss: 0.0133 - val_mse: 0.0133 - val_mae: 0.0863\n",
      "Epoch 61/150\n",
      "577/577 [==============================] - 0s 64us/sample - loss: 0.0154 - mse: 0.0154 - mae: 0.0930 - val_loss: 0.0133 - val_mse: 0.0133 - val_mae: 0.0865\n",
      "Epoch 62/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0153 - mse: 0.0153 - mae: 0.0924 - val_loss: 0.0130 - val_mse: 0.0130 - val_mae: 0.0851\n",
      "Epoch 63/150\n",
      "577/577 [==============================] - 0s 71us/sample - loss: 0.0154 - mse: 0.0154 - mae: 0.0927 - val_loss: 0.0132 - val_mse: 0.0132 - val_mae: 0.0858\n",
      "Epoch 64/150\n",
      "577/577 [==============================] - 0s 66us/sample - loss: 0.0154 - mse: 0.0154 - mae: 0.0921 - val_loss: 0.0131 - val_mse: 0.0131 - val_mae: 0.0856\n",
      "Epoch 65/150\n",
      "577/577 [==============================] - 0s 85us/sample - loss: 0.0153 - mse: 0.0153 - mae: 0.0931 - val_loss: 0.0134 - val_mse: 0.0134 - val_mae: 0.0870\n",
      "Epoch 66/150\n",
      "577/577 [==============================] - 0s 64us/sample - loss: 0.0151 - mse: 0.0151 - mae: 0.0918 - val_loss: 0.0129 - val_mse: 0.0129 - val_mae: 0.0848\n",
      "Epoch 67/150\n",
      "577/577 [==============================] - 0s 101us/sample - loss: 0.0151 - mse: 0.0151 - mae: 0.0914 - val_loss: 0.0130 - val_mse: 0.0130 - val_mae: 0.0852\n",
      "Epoch 68/150\n",
      "577/577 [==============================] - 0s 66us/sample - loss: 0.0150 - mse: 0.0150 - mae: 0.0914 - val_loss: 0.0132 - val_mse: 0.0132 - val_mae: 0.0863\n",
      "Epoch 69/150\n",
      "577/577 [==============================] - 0s 97us/sample - loss: 0.0150 - mse: 0.0150 - mae: 0.0914 - val_loss: 0.0131 - val_mse: 0.0131 - val_mae: 0.0859\n",
      "Epoch 70/150\n",
      "577/577 [==============================] - 0s 75us/sample - loss: 0.0149 - mse: 0.0149 - mae: 0.0916 - val_loss: 0.0129 - val_mse: 0.0129 - val_mae: 0.0851\n",
      "Epoch 71/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0149 - mse: 0.0149 - mae: 0.0909 - val_loss: 0.0128 - val_mse: 0.0128 - val_mae: 0.0843\n",
      "Epoch 72/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0148 - mse: 0.0148 - mae: 0.0906 - val_loss: 0.0127 - val_mse: 0.0127 - val_mae: 0.0841\n",
      "Epoch 73/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0147 - mse: 0.0147 - mae: 0.0909 - val_loss: 0.0129 - val_mse: 0.0129 - val_mae: 0.0850\n",
      "Epoch 74/150\n",
      "577/577 [==============================] - 0s 64us/sample - loss: 0.0147 - mse: 0.0147 - mae: 0.0903 - val_loss: 0.0125 - val_mse: 0.0125 - val_mae: 0.0832\n",
      "Epoch 75/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0147 - mse: 0.0147 - mae: 0.0903 - val_loss: 0.0131 - val_mse: 0.0131 - val_mae: 0.0863\n",
      "Epoch 76/150\n",
      "577/577 [==============================] - 0s 64us/sample - loss: 0.0147 - mse: 0.0147 - mae: 0.0901 - val_loss: 0.0124 - val_mse: 0.0124 - val_mae: 0.0825\n",
      "Epoch 77/150\n",
      "577/577 [==============================] - 0s 64us/sample - loss: 0.0145 - mse: 0.0145 - mae: 0.0896 - val_loss: 0.0126 - val_mse: 0.0126 - val_mae: 0.0841\n",
      "Epoch 78/150\n",
      "577/577 [==============================] - 0s 65us/sample - loss: 0.0144 - mse: 0.0144 - mae: 0.0896 - val_loss: 0.0124 - val_mse: 0.0124 - val_mae: 0.0833\n",
      "Epoch 79/150\n",
      "577/577 [==============================] - 0s 73us/sample - loss: 0.0143 - mse: 0.0143 - mae: 0.0888 - val_loss: 0.0125 - val_mse: 0.0125 - val_mae: 0.0836\n",
      "Epoch 80/150\n",
      "577/577 [==============================] - 0s 69us/sample - loss: 0.0143 - mse: 0.0143 - mae: 0.0896 - val_loss: 0.0124 - val_mse: 0.0124 - val_mae: 0.0831\n",
      "Epoch 81/150\n",
      "577/577 [==============================] - 0s 64us/sample - loss: 0.0143 - mse: 0.0143 - mae: 0.0884 - val_loss: 0.0123 - val_mse: 0.0123 - val_mae: 0.0825\n",
      "Epoch 82/150\n",
      "577/577 [==============================] - 0s 66us/sample - loss: 0.0142 - mse: 0.0142 - mae: 0.0888 - val_loss: 0.0123 - val_mse: 0.0123 - val_mae: 0.0829\n",
      "Epoch 83/150\n",
      "577/577 [==============================] - 0s 66us/sample - loss: 0.0141 - mse: 0.0141 - mae: 0.0879 - val_loss: 0.0121 - val_mse: 0.0121 - val_mae: 0.0817\n",
      "Epoch 84/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0140 - mse: 0.0140 - mae: 0.0876 - val_loss: 0.0121 - val_mse: 0.0121 - val_mae: 0.0822\n",
      "Epoch 85/150\n",
      "577/577 [==============================] - 0s 71us/sample - loss: 0.0140 - mse: 0.0140 - mae: 0.0881 - val_loss: 0.0121 - val_mse: 0.0121 - val_mae: 0.0826\n",
      "Epoch 86/150\n",
      "577/577 [==============================] - 0s 66us/sample - loss: 0.0142 - mse: 0.0142 - mae: 0.0892 - val_loss: 0.0120 - val_mse: 0.0120 - val_mae: 0.0816\n",
      "Epoch 87/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0139 - mse: 0.0139 - mae: 0.0873 - val_loss: 0.0122 - val_mse: 0.0122 - val_mae: 0.0829\n",
      "Epoch 88/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0138 - mse: 0.0138 - mae: 0.0868 - val_loss: 0.0119 - val_mse: 0.0119 - val_mae: 0.0816\n",
      "Epoch 89/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0137 - mse: 0.0137 - mae: 0.0865 - val_loss: 0.0118 - val_mse: 0.0118 - val_mae: 0.0811\n",
      "Epoch 90/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0137 - mse: 0.0137 - mae: 0.0875 - val_loss: 0.0120 - val_mse: 0.0120 - val_mae: 0.0821\n",
      "Epoch 91/150\n",
      "577/577 [==============================] - 0s 73us/sample - loss: 0.0138 - mse: 0.0138 - mae: 0.0866 - val_loss: 0.0118 - val_mse: 0.0118 - val_mae: 0.0813\n",
      "Epoch 92/150\n",
      "577/577 [==============================] - 0s 85us/sample - loss: 0.0136 - mse: 0.0136 - mae: 0.0868 - val_loss: 0.0120 - val_mse: 0.0120 - val_mae: 0.0828\n",
      "Epoch 93/150\n",
      "577/577 [==============================] - 0s 66us/sample - loss: 0.0135 - mse: 0.0135 - mae: 0.0861 - val_loss: 0.0116 - val_mse: 0.0116 - val_mae: 0.0799\n",
      "Epoch 94/150\n",
      "577/577 [==============================] - 0s 83us/sample - loss: 0.0136 - mse: 0.0136 - mae: 0.0861 - val_loss: 0.0116 - val_mse: 0.0116 - val_mae: 0.0803\n",
      "Epoch 95/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0135 - mse: 0.0135 - mae: 0.0851 - val_loss: 0.0116 - val_mse: 0.0116 - val_mae: 0.0804\n",
      "Epoch 96/150\n",
      "577/577 [==============================] - 0s 73us/sample - loss: 0.0134 - mse: 0.0134 - mae: 0.0861 - val_loss: 0.0118 - val_mse: 0.0118 - val_mae: 0.0817\n",
      "Epoch 97/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577/577 [==============================] - 0s 71us/sample - loss: 0.0134 - mse: 0.0134 - mae: 0.0853 - val_loss: 0.0115 - val_mse: 0.0115 - val_mae: 0.0800\n",
      "Epoch 98/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0135 - mse: 0.0135 - mae: 0.0864 - val_loss: 0.0114 - val_mse: 0.0114 - val_mae: 0.0794\n",
      "Epoch 99/150\n",
      "577/577 [==============================] - 0s 69us/sample - loss: 0.0133 - mse: 0.0133 - mae: 0.0844 - val_loss: 0.0114 - val_mse: 0.0114 - val_mae: 0.0795\n",
      "Epoch 100/150\n",
      "577/577 [==============================] - 0s 87us/sample - loss: 0.0132 - mse: 0.0132 - mae: 0.0852 - val_loss: 0.0116 - val_mse: 0.0116 - val_mae: 0.0812\n",
      "Epoch 101/150\n",
      "577/577 [==============================] - 0s 66us/sample - loss: 0.0132 - mse: 0.0132 - mae: 0.0852 - val_loss: 0.0113 - val_mse: 0.0113 - val_mae: 0.0792\n",
      "Epoch 102/150\n",
      "577/577 [==============================] - 0s 66us/sample - loss: 0.0132 - mse: 0.0132 - mae: 0.0840 - val_loss: 0.0115 - val_mse: 0.0115 - val_mae: 0.0804\n",
      "Epoch 103/150\n",
      "577/577 [==============================] - 0s 66us/sample - loss: 0.0132 - mse: 0.0132 - mae: 0.0851 - val_loss: 0.0114 - val_mse: 0.0114 - val_mae: 0.0798\n",
      "Epoch 104/150\n",
      "577/577 [==============================] - 0s 62us/sample - loss: 0.0131 - mse: 0.0131 - mae: 0.0849 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0790\n",
      "Epoch 105/150\n",
      "577/577 [==============================] - 0s 67us/sample - loss: 0.0131 - mse: 0.0131 - mae: 0.0840 - val_loss: 0.0114 - val_mse: 0.0114 - val_mae: 0.0802\n",
      "Epoch 106/150\n",
      "577/577 [==============================] - 0s 67us/sample - loss: 0.0133 - mse: 0.0133 - mae: 0.0864 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0775\n",
      "Epoch 107/150\n",
      "577/577 [==============================] - 0s 64us/sample - loss: 0.0135 - mse: 0.0135 - mae: 0.0842 - val_loss: 0.0116 - val_mse: 0.0116 - val_mae: 0.0815\n",
      "Epoch 108/150\n",
      "577/577 [==============================] - 0s 69us/sample - loss: 0.0133 - mse: 0.0133 - mae: 0.0868 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0790\n",
      "Epoch 109/150\n",
      "577/577 [==============================] - 0s 64us/sample - loss: 0.0131 - mse: 0.0131 - mae: 0.0837 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0793\n",
      "Epoch 110/150\n",
      "577/577 [==============================] - 0s 76us/sample - loss: 0.0130 - mse: 0.0130 - mae: 0.0844 - val_loss: 0.0113 - val_mse: 0.0113 - val_mae: 0.0797\n",
      "Epoch 111/150\n",
      "577/577 [==============================] - 0s 70us/sample - loss: 0.0129 - mse: 0.0129 - mae: 0.0829 - val_loss: 0.0111 - val_mse: 0.0111 - val_mae: 0.0787\n",
      "Epoch 112/150\n",
      "577/577 [==============================] - 0s 73us/sample - loss: 0.0129 - mse: 0.0129 - mae: 0.0843 - val_loss: 0.0113 - val_mse: 0.0113 - val_mae: 0.0801\n",
      "Epoch 113/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0129 - mse: 0.0129 - mae: 0.0830 - val_loss: 0.0111 - val_mse: 0.0111 - val_mae: 0.0787\n",
      "Epoch 114/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0129 - mse: 0.0129 - mae: 0.0848 - val_loss: 0.0111 - val_mse: 0.0111 - val_mae: 0.0786\n",
      "Epoch 115/150\n",
      "577/577 [==============================] - 0s 66us/sample - loss: 0.0128 - mse: 0.0128 - mae: 0.0828 - val_loss: 0.0111 - val_mse: 0.0111 - val_mae: 0.0787\n",
      "Epoch 116/150\n",
      "577/577 [==============================] - 0s 69us/sample - loss: 0.0127 - mse: 0.0127 - mae: 0.0833 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0794\n",
      "Epoch 117/150\n",
      "577/577 [==============================] - 0s 66us/sample - loss: 0.0127 - mse: 0.0127 - mae: 0.0830 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0779\n",
      "Epoch 118/150\n",
      "577/577 [==============================] - 0s 66us/sample - loss: 0.0128 - mse: 0.0128 - mae: 0.0826 - val_loss: 0.0114 - val_mse: 0.0114 - val_mae: 0.0809\n",
      "Epoch 119/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0127 - mse: 0.0127 - mae: 0.0836 - val_loss: 0.0111 - val_mse: 0.0111 - val_mae: 0.0788\n",
      "Epoch 120/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0126 - mse: 0.0126 - mae: 0.0826 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0796\n",
      "Epoch 121/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0127 - mse: 0.0127 - mae: 0.0835 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0785\n",
      "Epoch 122/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0126 - mse: 0.0126 - mae: 0.0820 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0782\n",
      "Epoch 123/150\n",
      "577/577 [==============================] - 0s 83us/sample - loss: 0.0127 - mse: 0.0127 - mae: 0.0829 - val_loss: 0.0111 - val_mse: 0.0111 - val_mae: 0.0791\n",
      "Epoch 124/150\n",
      "577/577 [==============================] - 0s 62us/sample - loss: 0.0126 - mse: 0.0126 - mae: 0.0813 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0781\n",
      "Epoch 125/150\n",
      "577/577 [==============================] - 0s 66us/sample - loss: 0.0126 - mse: 0.0126 - mae: 0.0831 - val_loss: 0.0113 - val_mse: 0.0113 - val_mae: 0.0801\n",
      "Epoch 126/150\n",
      "577/577 [==============================] - 0s 64us/sample - loss: 0.0125 - mse: 0.0125 - mae: 0.0818 - val_loss: 0.0111 - val_mse: 0.0111 - val_mae: 0.0787\n",
      "Epoch 127/150\n",
      "577/577 [==============================] - 0s 75us/sample - loss: 0.0124 - mse: 0.0124 - mae: 0.0821 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0799\n",
      "Epoch 128/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0124 - mse: 0.0124 - mae: 0.0821 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0779\n",
      "Epoch 129/150\n",
      "577/577 [==============================] - 0s 94us/sample - loss: 0.0125 - mse: 0.0125 - mae: 0.0813 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0799\n",
      "Epoch 130/150\n",
      "577/577 [==============================] - 0s 71us/sample - loss: 0.0125 - mse: 0.0125 - mae: 0.0826 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0774\n",
      "Epoch 131/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0125 - mse: 0.0125 - mae: 0.0821 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0798\n",
      "Epoch 132/150\n",
      "577/577 [==============================] - 0s 66us/sample - loss: 0.0126 - mse: 0.0126 - mae: 0.0810 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0795\n",
      "Epoch 133/150\n",
      "577/577 [==============================] - 0s 66us/sample - loss: 0.0123 - mse: 0.0123 - mae: 0.0816 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0796\n",
      "Epoch 134/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0123 - mse: 0.0123 - mae: 0.0815 - val_loss: 0.0111 - val_mse: 0.0111 - val_mae: 0.0791\n",
      "Epoch 135/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0123 - mse: 0.0123 - mae: 0.0814 - val_loss: 0.0113 - val_mse: 0.0113 - val_mae: 0.0803\n",
      "Epoch 136/150\n",
      "577/577 [==============================] - 0s 69us/sample - loss: 0.0123 - mse: 0.0123 - mae: 0.0811 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0779\n",
      "Epoch 137/150\n",
      "577/577 [==============================] - 0s 88us/sample - loss: 0.0123 - mse: 0.0123 - mae: 0.0814 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0781\n",
      "Epoch 138/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0123 - mse: 0.0123 - mae: 0.0808 - val_loss: 0.0111 - val_mse: 0.0111 - val_mae: 0.0791\n",
      "Epoch 139/150\n",
      "577/577 [==============================] - 0s 99us/sample - loss: 0.0123 - mse: 0.0123 - mae: 0.0811 - val_loss: 0.0113 - val_mse: 0.0113 - val_mae: 0.0804\n",
      "Epoch 140/150\n",
      "577/577 [==============================] - 0s 104us/sample - loss: 0.0122 - mse: 0.0122 - mae: 0.0814 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0783\n",
      "Epoch 141/150\n",
      "577/577 [==============================] - 0s 71us/sample - loss: 0.0122 - mse: 0.0122 - mae: 0.0807 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0783\n",
      "Epoch 142/150\n",
      "577/577 [==============================] - 0s 66us/sample - loss: 0.0122 - mse: 0.0122 - mae: 0.0808 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0788\n",
      "Epoch 143/150\n",
      "577/577 [==============================] - 0s 76us/sample - loss: 0.0122 - mse: 0.0122 - mae: 0.0805 - val_loss: 0.0111 - val_mse: 0.0111 - val_mae: 0.0790\n",
      "Epoch 144/150\n",
      "577/577 [==============================] - 0s 102us/sample - loss: 0.0123 - mse: 0.0123 - mae: 0.0812 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0802\n",
      "Epoch 145/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577/577 [==============================] - 0s 64us/sample - loss: 0.0122 - mse: 0.0122 - mae: 0.0811 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0776\n",
      "Epoch 146/150\n",
      "577/577 [==============================] - 0s 69us/sample - loss: 0.0121 - mse: 0.0121 - mae: 0.0801 - val_loss: 0.0111 - val_mse: 0.0111 - val_mae: 0.0791\n",
      "Epoch 147/150\n",
      "577/577 [==============================] - 0s 66us/sample - loss: 0.0123 - mse: 0.0123 - mae: 0.0819 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0777\n",
      "Epoch 148/150\n",
      "577/577 [==============================] - 0s 68us/sample - loss: 0.0122 - mse: 0.0122 - mae: 0.0803 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0798\n",
      "Epoch 149/150\n",
      "577/577 [==============================] - 0s 66us/sample - loss: 0.0122 - mse: 0.0122 - mae: 0.0803 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0796\n",
      "Epoch 150/150\n",
      "577/577 [==============================] - 0s 73us/sample - loss: 0.0122 - mse: 0.0122 - mae: 0.0810 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0784\n"
     ]
    }
   ],
   "source": [
    ">>> history = model.fit(X_train, y_train, epochs=150, batch_size=50,  verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mse', 'mae', 'val_loss', 'val_mse', 'val_mae'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnew = np.array([[40, 0, 26, 9000, 8000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[  40.    0.   26. 9000. 8000.], Predicted=[13918.433]\n"
     ]
    }
   ],
   "source": [
    "Xnew = np.array([[40, 0, 26, 9000, 8000]])\n",
    "Xnew= scaler_x.transform(Xnew)\n",
    "ynew= model.predict(Xnew)\n",
    "#invert normalize\n",
    "ynew = scaler_y.inverse_transform(ynew) \n",
    "Xnew = scaler_x.inverse_transform(Xnew)\n",
    "print(\"X=%s, Predicted=%s\" % (Xnew[0], ynew[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
